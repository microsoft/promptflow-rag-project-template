{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from langchain.document_loaders import DirectoryLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.docstore.document import Document\n",
    "from abc import ABC, abstractmethod"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Please make sure you have already run the \"../../../preprocessing/step0_data_preprocessor.ipynb\" notebook to obtain DATA from the source (e.g. blobstorage)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "docx_loader = DirectoryLoader(\"../../../preprocessing/DATA\", glob=\"**/*.docx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = docx_loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "\n",
    "def extract_info_from_filename(filename):\n",
    "    \"\"\"\n",
    "    Input: filename (\"MSFTTranscriptFY23Q4\")\n",
    "    Output: Extract stock symbol, year and quarter from filename\n",
    "    \"\"\"\n",
    "    pattern = r\"([A-Z]+)TranscriptFY(\\d{2})Q(\\d)\"\n",
    "    match = re.search(pattern, filename)\n",
    "\n",
    "    if match:\n",
    "        symbol = match.group(1)\n",
    "        fiscal_year = match.group(2)\n",
    "        fiscal_quarter = match.group(3)\n",
    "        return symbol, fiscal_year, fiscal_quarter\n",
    "    else:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_chunks = []\n",
    "\n",
    "for doc in docs:\n",
    "    source = doc.metadata[\"source\"]\n",
    "    symbol, fiscal_year, fiscal_quarter = extract_info_from_filename(source)\n",
    "\n",
    "    text_splitter = RecursiveCharacterTextSplitter(\n",
    "        separators=[\n",
    "            \"\\n## \",\n",
    "            \"\\n### \",\n",
    "            \"\\n#### \",\n",
    "            \"\\n##### \",\n",
    "            \"\\n###### \",\n",
    "            \"```\\n\\n\",\n",
    "            \"\\n\\n***\\n\\n\",\n",
    "            \"\\n\\n---\\n\\n\",\n",
    "            \"\\n\\n___\\n\\n\",\n",
    "            \"\\n\\n\",\n",
    "            \"\\n\",\n",
    "            \" \",\n",
    "            \"\",\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    chunks = text_splitter.split_text(doc.page_content)\n",
    "    for i, chunk in enumerate(chunks):\n",
    "        doc = Document(\n",
    "            page_content=chunk,\n",
    "            metadata={\n",
    "                \"source\": source,\n",
    "                \"symbol\": symbol,\n",
    "                \"fiscal_year\": fiscal_year,\n",
    "                \"fiscal_quarter\": fiscal_quarter,\n",
    "                \"chunk\": i,\n",
    "            },\n",
    "        )\n",
    "        doc_chunks.append(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(doc_chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import dotenv_values\n",
    "from azure.keyvault.secrets import SecretClient\n",
    "from azure.identity import DefaultAzureCredential\n",
    "import openai\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "import requests\n",
    "\n",
    "# specify the name of the .env file name\n",
    "env_name = \"../../../../.env\"  # change to your own .env file name\n",
    "config = dotenv_values(env_name)\n",
    "\n",
    "if config[\"KEYS_FROM\"] == \"KEYVAULT\":\n",
    "    print(\"keyvault was selected.\")\n",
    "    keyVaultName = config[\"KEY_VAULT_NAME\"]\n",
    "    KVUri = f\"https://{keyVaultName}.vault.azure.net\"\n",
    "\n",
    "    credential = DefaultAzureCredential()\n",
    "    client = SecretClient(vault_url=KVUri, credential=credential)\n",
    "\n",
    "    openai.api_type = client.get_secret(\"OPENAI-API-TYPE\").value\n",
    "    openai.api_key = client.get_secret(\"OPENAI-API-KEY\").value\n",
    "    openai.api_base = client.get_secret(\"OPENAI-API-BASE\").value\n",
    "    openai.api_version = client.get_secret(\"OPENAI-API-VERSION\").value\n",
    "    deployment_embedding = client.get_secret(\"OPENAI-DEPLOYMENT-EMBEDDING\").value\n",
    "else:\n",
    "    openai.api_type = config[\"OPENAI_API_TYPE\"]\n",
    "    openai.api_key = config[\"OPENAI_API_KEY\"]\n",
    "    openai.api_base = config[\"OPENAI_API_BASE\"]\n",
    "    openai.api_version = config[\"OPENAI_API_VERSION\"]\n",
    "    deployment_embedding = config[\"OPENAI_DEPLOYMENT_EMBEDDING\"]\n",
    "\n",
    "\n",
    "def createEmbeddings(text, endpoint, api_key, api_version, embedding_model_deployment):\n",
    "    request_url = f\"{endpoint}/openai/deployments/{embedding_model_deployment}/embeddings?api-version={api_version}\"\n",
    "    headers = {\"Content-Type\": \"application/json\", \"api-key\": api_key}\n",
    "    request_payload = {\"input\": text}\n",
    "    embedding_response = requests.post(\n",
    "        request_url, json=request_payload, headers=headers, timeout=None\n",
    "    )\n",
    "    if embedding_response.status_code == 200:\n",
    "        data_values = embedding_response.json()[\"data\"]\n",
    "        embeddings_vectors = [data_value[\"embedding\"] for data_value in data_values]\n",
    "        return embeddings_vectors\n",
    "    else:\n",
    "        raise Exception(f\"failed to get embedding: {embedding_response.json()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.keyvault.secrets import SecretClient\n",
    "from azure.identity import DefaultAzureCredential\n",
    "from dotenv import dotenv_values\n",
    "\n",
    "config = dotenv_values(env_name)\n",
    "\n",
    "if config[\"KEYS_FROM\"] == \"KEYVAULT\":\n",
    "    print(\"keyvault was selected.\")\n",
    "    keyVaultName = config[\"KEY_VAULT_NAME\"]\n",
    "    KVUri = f\"https://{keyVaultName}.vault.azure.net\"\n",
    "\n",
    "    credential = DefaultAzureCredential()\n",
    "    client = SecretClient(vault_url=KVUri, credential=credential)\n",
    "    MONGO_CONN = (client.get_secret(\"COSMOS-DB-MONGO-URI\").value,)\n",
    "else:\n",
    "    print(\".env was selected.\")\n",
    "    MONGO_CONN = config[\"COSMOS_DB_MONGO_URI\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pymongo\n",
    "from pymongo import MongoClient\n",
    "from pymongo.errors import ConnectionFailure\n",
    "from abc import ABC, abstractmethod\n",
    "\n",
    "\n",
    "class DatabaseService(ABC):\n",
    "    @abstractmethod\n",
    "    def store_data(self, data):\n",
    "        pass\n",
    "\n",
    "    @abstractmethod\n",
    "    def retrieve_data(self, query, num_results):\n",
    "        pass\n",
    "\n",
    "\n",
    "SEARCH_INDEX_NAME = \"vectorSearchIndex\"\n",
    "\n",
    "\n",
    "class MongoDBService(DatabaseService):\n",
    "    def __init__(self, db_name, collection_name, search_index_name=SEARCH_INDEX_NAME):\n",
    "        self.db_name = db_name\n",
    "        self.collection_name = collection_name\n",
    "        self.search_index_name = search_index_name\n",
    "        self.client = MongoClient(MONGO_CONN)\n",
    "        self.db = self.client[self.db_name]\n",
    "        self.collection = self.db[self.collection_name]\n",
    "        self._create_database()\n",
    "        self._create_search_index()\n",
    "        self._create_filter_search_index()\n",
    "\n",
    "    def _create_schema(self, docs):\n",
    "        data = []\n",
    "        for i, doc in enumerate(docs):\n",
    "            # Create embeddings using the provided function\n",
    "            embeddings = createEmbeddings(\n",
    "                doc.page_content,\n",
    "                openai.api_base,\n",
    "                openai.api_key,\n",
    "                openai.api_version,\n",
    "                deployment_embedding,\n",
    "            )[0]\n",
    "            data.append(\n",
    "                {\n",
    "                    \"id\": i,\n",
    "                    \"content\": doc.page_content,\n",
    "                    \"contentVector\": embeddings,\n",
    "                    \"symbol\": doc.metadata[\"symbol\"],\n",
    "                    \"fiscal_year\": doc.metadata[\"fiscal_year\"],\n",
    "                    \"fiscal_quarter\": doc.metadata[\"fiscal_quarter\"],\n",
    "                    \"source\": doc.metadata[\"source\"],\n",
    "                    \"chunkid\": doc.metadata[\"chunk\"],\n",
    "                }\n",
    "            )\n",
    "        return data\n",
    "\n",
    "    def _create_database(self):\n",
    "        # Check if the collection already exists, and create it if needed\n",
    "        if self.collection_name not in self.db.list_collection_names():\n",
    "            self.db.create_collection(self.collection_name)\n",
    "            print(\"Created collection '{}'.\".format(self.collection_name))\n",
    "        else:\n",
    "            print(\"Using collection: '{}'.\".format(self.collection_name))\n",
    "\n",
    "    def _create_search_index(self):\n",
    "        self.db.command(\n",
    "            {\n",
    "                \"createIndexes\": self.collection_name,\n",
    "                \"indexes\": [\n",
    "                    {\n",
    "                        \"name\": self.search_index_name,\n",
    "                        \"key\": {\"contentVector\": \"cosmosSearch\"},\n",
    "                        \"cosmosSearchOptions\": {\n",
    "                            \"kind\": \"vector-ivf\",\n",
    "                            \"numLists\": 1,\n",
    "                            \"similarity\": \"COS\",  # TODO: Add other similarity options.\n",
    "                            \"dimensions\": 1536,\n",
    "                        },\n",
    "                    }\n",
    "                ],\n",
    "            }\n",
    "        )\n",
    "    \n",
    "    def _create_filter_search_index(self):\n",
    "        self.db.command({\n",
    "            \"createIndexes\": self.collection_name, \n",
    "            \"indexes\": [\n",
    "            {\n",
    "                \"key\": { \n",
    "                    \"symbol\": 1 \n",
    "                    }, \n",
    "                \"name\": \"symbol_filter\" \n",
    "            },\n",
    "            {\n",
    "                \"key\": { \n",
    "                    \"fiscal_year\": 1 \n",
    "                    }, \n",
    "                \"name\": \"fiscal_year_filter\" \n",
    "            },\n",
    "            {\n",
    "                \"key\": { \n",
    "                    \"fiscal_quarter\": 1 \n",
    "                    }, \n",
    "                \"name\": \"fiscal_quarter_filter\" \n",
    "            }\n",
    "            ] \n",
    "        }\n",
    "        )  \n",
    "    def _drop_data(self):\n",
    "        self.collection.drop_index(self.search_index_name)\n",
    "        self.client.drop_database(self.db_name)\n",
    "\n",
    "    def store_data(self, data):\n",
    "        try:\n",
    "            # Insert data into the collection\n",
    "            self.collection.insert_many(data)\n",
    "            print(\"Data inserted successfully.\")\n",
    "        except Exception as e:\n",
    "            print(\"Failed to insert data: \", e)\n",
    "\n",
    "    def insert_one(self, entry):\n",
    "        self.collection.insert_one(entry)\n",
    "\n",
    "    def retrieve_data(self, query, num_results=1):\n",
    "        try:\n",
    "            # Perform a vector search query\n",
    "            pipeline = [\n",
    "                {\n",
    "                    \"$search\": {\n",
    "                        \"cosmosSearch\": {\n",
    "                            \"vector\": query,\n",
    "                            \"path\": \"contentVector\",\n",
    "                            \"k\": num_results,\n",
    "                        },\n",
    "                        \"returnStoredSource\": True,\n",
    "                    }\n",
    "                }\n",
    "            ]\n",
    "            results = list(self.collection.aggregate(pipeline))\n",
    "            return results\n",
    "        except Exception as e:\n",
    "            print(\"Search query failed: \", e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = MongoClient(MONGO_CONN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mongodb = MongoDBService(db_name=\"earning_calls\", collection_name=\"transcript_filter_vector\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = mongodb._create_schema(doc_chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mongodb.store_data(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mongodb.collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mydb = mongodb.db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "col = mydb[mongodb.collection_name]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify all indexes are present\n",
    "for i in col.list_indexes():\n",
    "    print(i)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "appliedaipf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
