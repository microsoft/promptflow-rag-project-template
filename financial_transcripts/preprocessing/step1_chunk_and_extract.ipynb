{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import dotenv_values\n",
    "from pathlib import Path\n",
    "import os\n",
    "import pandas as pd\n",
    "from azure.core.credentials import AzureKeyCredential\n",
    "from azure.ai.formrecognizer import DocumentAnalysisClient\n",
    "\n",
    "# specify the name of the .env file name \n",
    "env_name = \"../../llm.env\" # change to your own .env file name\n",
    "config = dotenv_values(env_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract data and context using Azure Form Recognizer\n",
    "\n",
    "This code sample shows Prebuilt Document operations with the Azure Form Recognizer client library. \n",
    "The async versions of the samples require Python 3.6 or later.\n",
    "\n",
    "To learn more, please visit the documentation - Quickstart: Form Recognizer Python client library SDKs\n",
    "https://docs.microsoft.com/en-us/azure/applied-ai-services/form-recognizer/quickstarts/try-v3-python-sdk\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Remember to remove the key from your code when you're done, and never post it publicly. For production, use\n",
    "secure methods to store and access your credentials. For more information, see \n",
    "https://docs.microsoft.com/en-us/azure/cognitive-services/cognitive-services-security?tabs=command-line%2Ccsharp#environment-variables-and-application-configuration\n",
    "\"\"\"\n",
    "\n",
    "endpoint = config[\"AZURE_FORM_RECOGNIZER_ENDPOINT\"]\n",
    "key = config[\"AZURE_FORM_RECOGNIZER_KEY\"]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Read pdf files using Azure Form Recognizer and split into chunks \n",
    "Azure form recognizer reads pdf files and then we chunk the extracted text, and also save page number and line number for the extracted chunks "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "################################################################################\n",
    "#################### Helper Functions ##########################################\n",
    "################################################################################\n",
    "\n",
    "# Read pdf files\n",
    "def analyze_pdf(doc_path):  \n",
    "    with open(doc_path, \"rb\") as f:\n",
    "        poller = document_analysis_client.begin_analyze_document(\n",
    "            \"prebuilt-document\", document=f\n",
    "        )\n",
    "    result = poller.result()\n",
    "                \n",
    "    return result\n",
    "\n",
    "# Extract stock symbol, year, and quarter from filename\n",
    "def extract_info_from_filename(filename):\n",
    "    '''\n",
    "    Input: filename (\"MSFTTranscriptFY23Q4\")\n",
    "    Output: Extract stock symbol, year and quarter from filename\n",
    "    '''\n",
    "    pattern = r'([A-Z]+)TranscriptFY(\\d{2})Q(\\d)'\n",
    "    match = re.search(pattern, filename)\n",
    "    \n",
    "    if match:\n",
    "        symbol = match.group(1)\n",
    "        fiscal_year = match.group(2)\n",
    "        fiscal_quarter = match.group(3)\n",
    "        return symbol, fiscal_year, fiscal_quarter\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "# Extract line number and page number\n",
    "def create_line_page_tuples(result):\n",
    "    '''\n",
    "    Input: result of form recognizer analyze_pdf function\n",
    "    Output: Create list of tuples of the form (line, page_num, line_num) \n",
    "    This will keep reference of the line number and page number of each line in the document.\n",
    "    '''\n",
    "    line_page_tuples = []\n",
    "\n",
    "    total_pages = len(result.pages)\n",
    "    for page_num in range(total_pages):\n",
    "        lines = result.pages[page_num].lines\n",
    "        total_lines = len(lines)\n",
    "\n",
    "        for line_num in range(total_lines):\n",
    "            line = lines[line_num].content\n",
    "            line_page_tuples.append((line, page_num + 1, line_num + 1))\n",
    "\n",
    "    return line_page_tuples\n",
    "\n",
    "# Retrieve page number and chunks\n",
    "def chunk_with_page_number(line_page_tuples, chunk_length=10, chunk_overlap=2):\n",
    "    '''\n",
    "    Given the list of tuples of the form (line, page_num, line_num) and chunk length and overlap,\n",
    "    it will create chunks of text with page number and line number of the first line in the chunk.\n",
    "    chunk length: number of lines in each chunk\n",
    "    chunk_overlap: number of overlapping lines between chunks\n",
    "    '''\n",
    "    pointer = 0 \n",
    "    chunks = []\n",
    "    total_lines = len(line_page_tuples)\n",
    "    #for line, page_number, line_number in line_page_tuples:\n",
    "    while pointer < total_lines:\n",
    "        line_count = 0\n",
    "        current_chunk = \"\"\n",
    "        if not chunks: \n",
    "            # for first chunk we can not use overlap\n",
    "            pointer = 0\n",
    "        else:\n",
    "            pointer = pointer - chunk_overlap\n",
    "        \n",
    "        # take starting page number and line number \n",
    "        page_number, line_number = line_page_tuples[pointer][1:]  \n",
    "        while line_count < chunk_length and pointer < total_lines:\n",
    "            current_chunk = current_chunk + line_page_tuples[pointer][0]\n",
    "            current_chunk = current_chunk + \" \"\n",
    "            line_count += 1\n",
    "            pointer += 1\n",
    "        chunks.append((current_chunk, page_number, line_number))\n",
    "    return chunks\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "writing the results of: \n",
      "MSFTTranscriptFY23Q1.pdf\n",
      "writing the results of: \n",
      "MSFTTranscriptFY23Q2.pdf\n",
      "writing the results of: \n",
      "MSFTTranscriptFY23Q3.pdf\n",
      "writing the results of: \n",
      "MSFTTranscriptFY23Q4.pdf\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>Ticker</th>\n",
       "      <th>Year</th>\n",
       "      <th>Quarter</th>\n",
       "      <th>Chunk</th>\n",
       "      <th>PageNumber</th>\n",
       "      <th>LineNumber</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>MSFT</td>\n",
       "      <td>23</td>\n",
       "      <td>1</td>\n",
       "      <td>Microsoft FY23 First Quarter Earnings Conferen...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>MSFT</td>\n",
       "      <td>23</td>\n",
       "      <td>1</td>\n",
       "      <td>On the Microsoft Investor Relations website, y...</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>MSFT</td>\n",
       "      <td>23</td>\n",
       "      <td>1</td>\n",
       "      <td>GAAP. They are included as additional clarifyi...</td>\n",
       "      <td>1</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>MSFT</td>\n",
       "      <td>23</td>\n",
       "      <td>1</td>\n",
       "      <td>same in constant currency, we will refer to th...</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>MSFT</td>\n",
       "      <td>23</td>\n",
       "      <td>1</td>\n",
       "      <td>predictions, projections, or other statements ...</td>\n",
       "      <td>2</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Id Ticker Year Quarter                                              Chunk  \\\n",
       "0   1   MSFT   23       1  Microsoft FY23 First Quarter Earnings Conferen...   \n",
       "1   2   MSFT   23       1  On the Microsoft Investor Relations website, y...   \n",
       "2   3   MSFT   23       1  GAAP. They are included as additional clarifyi...   \n",
       "3   4   MSFT   23       1  same in constant currency, we will refer to th...   \n",
       "4   5   MSFT   23       1  predictions, projections, or other statements ...   \n",
       "\n",
       "   PageNumber  LineNumber  \n",
       "0           1           1  \n",
       "1           1           9  \n",
       "2           1          17  \n",
       "3           2           6  \n",
       "4           2          14  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define document analysis client\n",
    "document_analysis_client = DocumentAnalysisClient(\n",
    "        endpoint=endpoint, credential=AzureKeyCredential(key)\n",
    "    )\n",
    "\n",
    "doc_dir = Path(\"DATA/\")\n",
    "pdf_files = [filename for filename in os.listdir(doc_dir) if filename.endswith('.pdf')]\n",
    "\n",
    "dfs = []\n",
    "\n",
    "for file_name in pdf_files:\n",
    "    \n",
    "    values = extract_info_from_filename(file_name) # symbol, fiscal_year, fiscal_quarter\n",
    "    file_path = os.path.join(doc_dir, f\"{os.path.splitext(file_name)[0]}.pdf\")\n",
    "    \n",
    "    # analyze the pdf using form recognizer\n",
    "    result = analyze_pdf(file_path)\n",
    "    \n",
    "    # get the chunks in a tuple of the form (chunk, page_number, line_number)\n",
    "    line_page_tuples = create_line_page_tuples(result)\n",
    "    chunks = chunk_with_page_number(line_page_tuples=line_page_tuples, chunk_length=10, chunk_overlap=2)\n",
    "   \n",
    "    # Write results to dataframe \n",
    "    df_chunks = pd.DataFrame(chunks, columns = ['Chunk', 'PageNumber', 'LineNumber'])  \n",
    "\n",
    "    df_chunks[\"Ticker\"], df_chunks[\"Year\"], df_chunks[\"Quarter\"]  = \"NULL\", \"NULL\", \"NULL\"\n",
    "    if values:\n",
    "        symbol, fiscal_year, fiscal_quarter = values\n",
    "        df_chunks[\"Ticker\"], df_chunks[\"Year\"], df_chunks[\"Quarter\"]  = symbol, fiscal_year, fiscal_quarter\n",
    "        \n",
    "    # Reorder dataframe column name\n",
    "    new_column_order = ['Ticker', 'Year', 'Quarter', 'Chunk', 'PageNumber', 'LineNumber']\n",
    "    df_chunks = df_chunks[new_column_order]\n",
    "        \n",
    "    # Add all datframe to list\n",
    "    dfs.append(df_chunks)\n",
    "\n",
    "    # Saving results to csv files\n",
    "    if not os.path.exists(\"AnalyzedPDF/\"):\n",
    "        os.makedirs(\"AnalyzedPDF/\")\n",
    "\n",
    "    print('writing the results of: \\n' + file_name)  \n",
    "    if not os.path.exists(f\"AnalyzedPDF/Chunks_{file_name[0:-4]}.csv\"):\n",
    "        df_chunks.to_csv(f\"AnalyzedPDF/Chunks_{file_name[0:-4]}.csv\", index=False)\n",
    "    else:\n",
    "        print(f'File: chunks_{file_name}.csv already exists, skipping...')\n",
    "        \n",
    "## Combine all the files\n",
    "df = pd.concat(dfs, ignore_index=True)\n",
    "df = df.reset_index(drop=True)\n",
    "df.insert(0, 'Id', [i for i in range(1, df.shape[0]+1)]) # Add 'Id' column\n",
    "\n",
    "## Save to csv\n",
    "df.to_csv(\"AnalyzedPDF/Chunks.csv\", index=False)\n",
    "\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nanogpt",
   "language": "python",
   "name": "nanogpt"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
