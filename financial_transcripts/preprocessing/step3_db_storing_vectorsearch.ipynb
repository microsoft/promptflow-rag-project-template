{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Store chunks into Vector Database using Azure Cognitive Search (ACS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import pandas as pd\n",
    "import json  \n",
    "import openai  \n",
    "from dotenv import dotenv_values\n",
    "from tenacity import retry, wait_random_exponential, stop_after_attempt  \n",
    "from azure.core.credentials import AzureKeyCredential  \n",
    "from azure.keyvault.secrets import SecretClient\n",
    "from azure.identity import DefaultAzureCredential\n",
    "from azure.search.documents import SearchClient  \n",
    "from azure.search.documents.indexes import SearchIndexClient  \n",
    "from azure.search.documents.models import Vector  \n",
    "from azure.search.documents.indexes.models import (  \n",
    "    SearchIndex,  \n",
    "    SearchField,  \n",
    "    SearchFieldDataType,  \n",
    "    SimpleField,  \n",
    "    SearchableField,  \n",
    "    SearchIndex,  \n",
    "    SemanticConfiguration,  \n",
    "    PrioritizedFields,  \n",
    "    SemanticField,  \n",
    "    SearchField,  \n",
    "    SemanticSettings,  \n",
    "    VectorSearch,  \n",
    "    HnswVectorSearchAlgorithmConfiguration\n",
    ")\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from ast import literal_eval\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose name of index to create or update\n",
    "index_name = \"msft-transcripts\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load environment variables and keys "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "keyvault was selected.\n"
     ]
    }
   ],
   "source": [
    "# Specify the name of the .env file name \n",
    "env_name = \"../../.env\" # change to your own .env file name\n",
    "config = dotenv_values(env_name)\n",
    "\n",
    "if config['KEYS_FROM'] == \"KEYVAULT\":\n",
    "    print('keyvault was selected.')\n",
    "    keyVaultName = config[\"KEY_VAULT_NAME\"]\n",
    "    KVUri = f\"https://{keyVaultName}.vault.azure.net\"\n",
    "\n",
    "    credential = DefaultAzureCredential()\n",
    "    client = SecretClient(vault_url=KVUri, credential=credential)\n",
    "\n",
    "    # Azure OpenAI \n",
    "    openai.api_type = client.get_secret(\"OPENAI-API-TYPE\").value\n",
    "    openai.api_key = client.get_secret(\"OPENAI-API-KEY\").value\n",
    "    openai.api_base = client.get_secret(\"OPENAI-API-BASE\").value\n",
    "    openai.api_version = client.get_secret(\"OPENAI-API-VERSION\").value\n",
    "    deployment_embedding = client.get_secret(\"OPENAI-DEPLOYMENT-EMBEDDING\").value\n",
    "\n",
    "    ## Cog Search\n",
    "    cogsearch_key = client.get_secret(\"COGSEARCH-API-KEY\").value\n",
    "    service_endpoint = client.get_secret(\"COGSEARCH-ADDRESS\").value\n",
    "else:\n",
    "    # Azure OpenAI \n",
    "    openai.api_type = config[\"OPENAI_API_TYPE\"] #\"azure\"\n",
    "    openai.api_key = config['OPENAI_API_KEY']\n",
    "    openai.api_base = config['OPENAI_API_BASE']\n",
    "    openai.api_version = config['OPENAI_API_VERSION']\n",
    "    deployment_embedding = config[\"OPENAI_DEPLOYMENT_EMBEDDING\"]\n",
    "    \n",
    "    ## Cog Search\n",
    "    cogsearch_key = config[\"COGSEARCH_API_KEY\"]\n",
    "    service_endpoint = config[\"COGSEARCH_ADDRESS\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createEmbeddings(text, endpoint, api_key, api_version, embedding_model_deployment):\n",
    "    request_url = f\"{endpoint}/openai/deployments/{embedding_model_deployment}/embeddings?api-version={api_version}\"\n",
    "    headers = {\n",
    "        \"Content-Type\": \"application/json\",\n",
    "        \"api-key\": api_key\n",
    "    }\n",
    "    request_payload = {\n",
    "        'input': text\n",
    "    }\n",
    "    embedding_response = requests.post(request_url, json=request_payload, headers=headers, timeout=None)\n",
    "    if embedding_response.status_code == 200:\n",
    "        data_values = embedding_response.json()[\"data\"]\n",
    "        embeddings_vectors = [data_value[\"embedding\"] for data_value in data_values]\n",
    "        return embeddings_vectors\n",
    "    else:\n",
    "        raise Exception(f\"failed to get embedding: {embedding_response.json()}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Store the embeddings in Azure Cognitive Search Vector Store\n",
    "\n",
    "[AzureCogSearch](https://learn.microsoft.com/en-us/azure/search/search-what-is-azure-search) provides a simple interface to create a vector database, store and retrieve data using vector search. You can read more about [here](https://github.com/Azure/cognitive-search-vector-pr/tree/main) more about Vector Search.\n",
    "\n",
    "There are two steps to store data in AzureCogSearch vector database:\n",
    "- First, we create the index (or schema) of the vector database\n",
    "- Second, we add the chunked documents and their embeddings to the vector datastore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_chunks_embedding = pd.read_csv('AnalyzedPDF/ChunksEmbedding.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>Ticker</th>\n",
       "      <th>Year</th>\n",
       "      <th>Quarter</th>\n",
       "      <th>Chunk</th>\n",
       "      <th>PageNumber</th>\n",
       "      <th>LineNumber</th>\n",
       "      <th>Embedding</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>MSFT</td>\n",
       "      <td>23</td>\n",
       "      <td>1</td>\n",
       "      <td>Microsoft FY23 First Quarter Earnings Conferen...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>[-0.022691458, -0.02892966, -0.01939041, -0.02...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>MSFT</td>\n",
       "      <td>23</td>\n",
       "      <td>1</td>\n",
       "      <td>On the Microsoft Investor Relations website, y...</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>[-0.022940217, -0.0083436845, -0.008599305, -0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>MSFT</td>\n",
       "      <td>23</td>\n",
       "      <td>1</td>\n",
       "      <td>GAAP. They are included as additional clarifyi...</td>\n",
       "      <td>1</td>\n",
       "      <td>17</td>\n",
       "      <td>[-0.01130778, -0.0038822712, 0.003553209, -0.0...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Id Ticker  Year  Quarter  \\\n",
       "0   1   MSFT    23        1   \n",
       "1   2   MSFT    23        1   \n",
       "2   3   MSFT    23        1   \n",
       "\n",
       "                                               Chunk  PageNumber  LineNumber  \\\n",
       "0  Microsoft FY23 First Quarter Earnings Conferen...           1           1   \n",
       "1  On the Microsoft Investor Relations website, y...           1           9   \n",
       "2  GAAP. They are included as additional clarifyi...           1          17   \n",
       "\n",
       "                                           Embedding  \n",
       "0  [-0.022691458, -0.02892966, -0.01939041, -0.02...  \n",
       "1  [-0.022940217, -0.0083436845, -0.008599305, -0...  \n",
       "2  [-0.01130778, -0.0038822712, 0.003553209, -0.0...  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_chunks_embedding.head(3)\n",
    "#columns should look like the following with order preserved\n",
    "#Id, Chunk, PageNumber, LineNumber, DocId, Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " msft-transcripts created\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Create a search index\n",
    "index_client = SearchIndexClient(\n",
    "    endpoint=service_endpoint, credential=AzureKeyCredential(cogsearch_key)\n",
    ")\n",
    "fields = [\n",
    "    SimpleField(name=\"Id\", type=SearchFieldDataType.String, key=True, sortable=True, filterable=True, facetable=True),\n",
    "    SearchableField(name=\"Ticker\", type=SearchFieldDataType.String, filterable=True),\n",
    "    SearchableField(name=\"Year\", type=SearchFieldDataType.String, filterable=True),\n",
    "    SearchableField(name=\"Quarter\", type=SearchFieldDataType.String, filterable=True),\n",
    "    SearchableField(name=\"Chunk\", type=SearchFieldDataType.String, searchable=True),\n",
    "    SearchableField(name=\"PageNumber\", type=SearchFieldDataType.String, filterable=True),\n",
    "    SearchableField(name=\"LineNumber\", type=SearchFieldDataType.String, filterable=True),\n",
    "    \n",
    "    SearchField(name=\"Embedding\", type=SearchFieldDataType.Collection(SearchFieldDataType.Single),\n",
    "                searchable=True, vector_search_dimensions=1536, vector_search_configuration=\"my-vector-config\"),\n",
    "]\n",
    "\n",
    "vector_search = VectorSearch(\n",
    "    algorithm_configurations=[\n",
    "        HnswVectorSearchAlgorithmConfiguration(\n",
    "            name=\"my-vector-config\",\n",
    "            kind=\"hnsw\",\n",
    "            parameters={\n",
    "                \"m\": 4,\n",
    "                \"efConstruction\": 400,\n",
    "                \"efSearch\": 500,\n",
    "                \"metric\": \"cosine\"\n",
    "            }\n",
    "        )\n",
    "    ]\n",
    ")\n",
    "\n",
    "semantic_config = SemanticConfiguration(\n",
    "    name=\"my-semantic-config\",\n",
    "    prioritized_fields=PrioritizedFields(\n",
    "        title_field=SemanticField(field_name=\"Ticker\"),\n",
    "        prioritized_content_fields=[SemanticField(field_name=\"Chunk\")]\n",
    "    )\n",
    ")\n",
    "\n",
    "# Create the semantic settings with the configuration\n",
    "semantic_settings = SemanticSettings(configurations=[semantic_config])\n",
    "\n",
    "# Create the search index with the semantic settings\n",
    "index = SearchIndex(name=index_name, fields=fields,\n",
    "                    vector_search=vector_search, semantic_settings=semantic_settings)\n",
    "result = index_client.create_or_update_index(index)\n",
    "print(f' {result.name} created')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uploaded 442 payload\n"
     ]
    }
   ],
   "source": [
    "\n",
    "## Upload data to Index\n",
    "def batch_append_payload(df, search_client):\n",
    "    \"\"\"append payload for batch insertion (note: max 1000 rows per insertion) of embeddings to Cognitive Search\"\"\"\n",
    "    value_list = []\n",
    "    for index, row in df.iterrows():\n",
    "        value_list.append(\n",
    "            {\n",
    "                \"Id\": str(index),\n",
    "                \"Ticker\": row[\"Ticker\"],\n",
    "                \"Year\": str(row[\"Year\"]),\n",
    "                \"Quarter\": str(row[\"Quarter\"]),\n",
    "                \"Chunk\": row[\"Chunk\"],\n",
    "                \"PageNumber\": str(row[\"PageNumber\"]),\n",
    "                \"LineNumber\": str(row[\"LineNumber\"]),\n",
    "                \"Embedding\": literal_eval(row['Embedding']),\n",
    "            }\n",
    "        )\n",
    "        \n",
    "#         print(len(value_list))\n",
    "        \n",
    "        if len(value_list) >= 1000:\n",
    "            result = search_client.upload_documents(value_list)\n",
    "            print(f\"Uploaded {len(value_list)} payload\")\n",
    "            value_list = []\n",
    "    result = search_client.upload_documents(value_list)\n",
    "    print(f\"Uploaded {len(value_list)} payload\")\n",
    "    \n",
    "            \n",
    "            \n",
    "#     print('payload of size {}'.format(len(value_list)))\n",
    "\n",
    "    return value_list\n",
    "\n",
    "\n",
    "search_client = SearchClient(\n",
    "    endpoint=service_endpoint,\n",
    "    index_name=index_name,\n",
    "    credential=AzureKeyCredential(cogsearch_key)\n",
    ")\n",
    "payload = batch_append_payload(df_chunks_embedding, search_client)\n",
    " \n",
    "# print(f\"Uploaded {len(payload)} payload\") \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Search Types 1: Pure Vector Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_client = SearchClient(\n",
    "\tservice_endpoint,\n",
    "\tindex_name,\n",
    "\tcredential=AzureKeyCredential(cogsearch_key)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSFT\n",
      "2\n",
      "23\n",
      "Microsoft FY23 Second Quarter Earnings Conference Call Brett Iversen, Satya Nadella, Amy Hood Tuesday, January 24, 2023 BRETT IVERSEN: Good afternoon and thank you for joining us today. On the call with me are Satya Nadella, chairman and chief executive officer, Amy Hood, chief financial officer, Alice Jolla, chief accounting officer, and Keith Dolliver, deputy general counsel. On the Microsoft Investor Relations website, you can find our earnings press release and financial summary slide deck, which is intended to \n"
     ]
    }
   ],
   "source": [
    "# Pure Vector Search\n",
    "query = \"Microsoft earnings call for year 2023 for Quarter 2\"  \n",
    "\n",
    "query_embedding = createEmbeddings(\n",
    "    query,\n",
    "    openai.api_base,\n",
    "    openai.api_key,\n",
    "    openai.api_version,\n",
    "    deployment_embedding\n",
    ")[0]\n",
    "\n",
    "vector = Vector(value=query_embedding, k=3, fields=\"Embedding\")\n",
    "  \n",
    "results = search_client.search(  \n",
    "    search_text=None,  \n",
    "    vectors=[vector],\n",
    "    #select=[\"Ticker\", \"Quarter\", \"Year\"],\n",
    "    #top=3,\n",
    ")\n",
    "\n",
    "# results\n",
    "  \n",
    "for result in results: \n",
    "    print(result['Ticker'])\n",
    "    print(result['Quarter'])\n",
    "    print(result['Year'])\n",
    "    print(result['Chunk'])\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Search Types 2: Pure Filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ticker: MSFT\n",
      "Quarter: 1\n",
      "Year: 23\n",
      "Microsoft FY23 First Quarter Earnings Conference Call Brett Iversen, Satya Nadella, Amy Hood Tuesday, October 25, 2022 BRETT IVERSEN: Good afternoon and thank you for joining us today. On the call with me are Satya Nadella, chairman and chief executive officer, Amy Hood, chief financial officer, Alice Jolla, chief accounting officer, and Keith Dolliver, deputy general counsel. On the Microsoft Investor Relations website, you can find our earnings press release and financial summary slide deck, which is intended to \n",
      "\n"
     ]
    }
   ],
   "source": [
    "results = search_client.search(  \n",
    "    search_text=None,  \n",
    "    filter=\"(Ticker eq 'MSFT') and (Year eq '23') and (Quarter eq '1') \",\n",
    ")  \n",
    "\n",
    "for result in results:\n",
    "    print(f\"Ticker: {result['Ticker']}\")\n",
    "    print(f\"Quarter: {result['Quarter']}\") \n",
    "    print(f\"Year: {result['Year']}\") \n",
    "    print(result['Chunk'])\n",
    "    print()\n",
    "    break\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Search Types 3: Vector Search with filters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ticker: MSFT\n",
      "Quarter: 1\n",
      "Year: 23\n",
      "you're still seeing digitization. This is still the tailwind that helps customers solve problems. This is still the way to build growth and leverage in your business. And yet, you still want to optimize your workloads. You still want to run them the most efficiently so that you can then make room for new workload growth. We saw that across all segments. If there was one segment where I may have seen it a bit more, I would say, in the small or mid-sized segment of the market, that tends to be more through partner. We rely on partners to help customers do those same optimizations and prepare workloads. But it is that one point I know that people are focused on. \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Pure Vector Search with Filter\n",
    "query = \"What are the KPIs?\"  \n",
    "  \n",
    "query_embedding = createEmbeddings(\n",
    "    query,\n",
    "    openai.api_base,\n",
    "    openai.api_key,\n",
    "    openai.api_version,\n",
    "    deployment_embedding\n",
    ")[0]\n",
    "\n",
    "vector = Vector(value=query_embedding, k=3, fields=\"Embedding\")  \n",
    "\n",
    "results = search_client.search(  \n",
    "    search_text=None,  \n",
    "    vectors=[vector],\n",
    "    filter=\"(Ticker eq 'MSFT') and (Year eq '23') and (Quarter eq '1') \",\n",
    "    #select=[\"Ticker\", \"Quarter\", \"Year\"],\n",
    "    top=3,\n",
    ")  \n",
    "  \n",
    "for result in results:\n",
    "    print(f\"Ticker: {result['Ticker']}\")\n",
    "    print(f\"Quarter: {result['Quarter']}\") \n",
    "    print(f\"Year: {result['Year']}\") \n",
    "    print(result['Chunk'])\n",
    "    print()\n",
    "\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Search Types 4: Hybrid Search with filters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ticker: MSFT\n",
      "Quarter: 1\n",
      "Year: 23\n",
      "where we expected. And what we did see through the quarter is a real focus both by customers, but also by our sales and customer success teams on going proactively to customers and making sure we are helping them optimize their workloads. And as we went through the quarter and as, of course, the macroeconomic environment got more complicated, we continued to focus on that, because ultimately, those optimizations bring value even as budgets are still growing and budgeted spend is still growing. And so, it's this nuance of you're still seeing digitization. This is still the tailwind that helps customers solve problems. This is still the way to build growth and leverage in your \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Pure Vector Search with Filter\n",
    "query = \"What are the KPIs?\"  \n",
    "  \n",
    "query_embedding = createEmbeddings(\n",
    "    query,\n",
    "    openai.api_base,\n",
    "    openai.api_key,\n",
    "    openai.api_version,\n",
    "    deployment_embedding\n",
    ")[0]\n",
    "\n",
    "vector = Vector(value=query_embedding, k=3, fields=\"Embedding\")  \n",
    "\n",
    "results = search_client.search(  \n",
    "    search_text=query,  \n",
    "    vectors=[vector],\n",
    "    filter=\"(Ticker eq 'MSFT') and (Year eq '23') and (Quarter eq '1') \",\n",
    "#     select=[\"Ticker\", \"Quarter\", \"Year\"],\n",
    "    top=3,\n",
    ")  \n",
    "  \n",
    "for result in results:\n",
    "    print(f\"Ticker: {result['Ticker']}\")\n",
    "    print(f\"Quarter: {result['Quarter']}\") \n",
    "    print(f\"Year: {result['Year']}\") \n",
    "    print(result['Chunk'])\n",
    "    print()\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
