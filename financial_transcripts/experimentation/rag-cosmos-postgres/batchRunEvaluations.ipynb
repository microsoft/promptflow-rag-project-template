{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Goal\n",
    "Run flows using sdk and allowing for external configuration of RAG parameters. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check Connections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import promptflow\n",
    "\n",
    "pf = promptflow.PFClient()\n",
    "\n",
    "# List all the available connections\n",
    "for c in pf.connections.list():\n",
    "    print(c.name + \" (\" + c.type + \")\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test the flow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = pf.flows.test(\n",
    "    \"../../rag-cosmos-postgres/flow.dag.yaml\",\n",
    "    inputs={\n",
    "        \"chat_history\": [],\n",
    "        \"query\": \"What is the growth rate of Azure ML revenue in FY23Q1?\",\n",
    "    },\n",
    ")\n",
    "\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run the flow with the benchmark data file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flow_path = \"../../rag-cosmos-postgres/flow.dag.yaml\"\n",
    "data_path = \"../../datasets/evalset.csv\"\n",
    "\n",
    "column_mapping = {\n",
    "    \"chat_history\": \"${data.chat_history}\",\n",
    "    \"query\": \"${data.question}\",\n",
    "}\n",
    "\n",
    "run_postgres_topk3 = pf.run(flow=flow_path, data=data_path, column_mapping=column_mapping)\n",
    "pf.stream(run_postgres_topk3)\n",
    "print(run_postgres_topk3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pf.get_details(run_postgres_topk3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ddf = pf.get_details(run_postgres_topk3)\n",
    "#ddf.to_csv(\"checkoutput.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_flow_path = \"../../evaluator/eval_aistudio_score/\"\n",
    "data_path = \"../../datasets/evalset.csv\"\n",
    "\n",
    "eval_postgres_run_topk3 = pf.run(\n",
    "    flow=eval_flow_path,\n",
    "    run=run_postgres_topk3,\n",
    "    data=data_path,\n",
    "    column_mapping={\n",
    "        \"question\": \"${data.question}\",\n",
    "        \"answer\": \"${data.answer}\",\n",
    "        \"reply\": \"${run.outputs.reply}\",\n",
    "        \"context\": \"${run.outputs.fetched_docs}\",\n",
    "        \"log_params\": \"${run.outputs.log_params}\"\n",
    "    },\n",
    "    display_name=\"eval_postgres_aistudio_score_topk3\",\n",
    ")\n",
    "pf.stream(eval_postgres_run_topk3)\n",
    "print(eval_postgres_run_topk3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pf.get_details(eval_postgres_run_topk3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pf.get_metrics(eval_postgres_run_topk3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pf.visualize(eval_postgres_run_topk3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multiple runs \n",
    "Using config.yaml file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "import promptflow\n",
    "\n",
    "pf = promptflow.PFClient()\n",
    "\n",
    "with open(\"./runs_config.yaml\", \"r\") as file:\n",
    "    runs_config = yaml.safe_load(file)\n",
    "\n",
    "# Access the contents of the config.yaml file\n",
    "print(runs_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to update param_config systematically \n",
    "import os \n",
    "def update_param_config(flow_path, config):\n",
    "    base_dir = os.path.dirname(flow_path)\n",
    "    param_config_path = os.path.join(base_dir, 'param_config.yaml')\n",
    "\n",
    "    with open(param_config_path, 'r') as file:\n",
    "        param_dict = yaml.safe_load(file)\n",
    "\n",
    "    param_dict.update(config)\n",
    "\n",
    "    with open(param_config_path, 'w') as file:\n",
    "        yaml.dump(param_dict, file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "run_time = datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "\n",
    "\n",
    "def run_dags(\n",
    "    flow_path=\"../../rag-cosmos-postgres/flow.dag.yaml\",\n",
    "    data_path=\"../../datasets/evalset.csv\",\n",
    "    eval_flow_path=\"../../evaluator/eval_aistudio_score/\",\n",
    "    config=None,\n",
    "):\n",
    "    column_mapping = {\n",
    "        \"chat_history\": \"${data.chat_history}\",\n",
    "        \"query\": \"${data.question}\",\n",
    "    }\n",
    "    update_param_config(flow_path, config)\n",
    "\n",
    "    copilot_run_from_config = pf.run(\n",
    "        flow=flow_path,\n",
    "        data=data_path,\n",
    "        column_mapping=column_mapping,\n",
    "        display_name=\"rag_postgres_run_from_config_\" + run_time,\n",
    "    )\n",
    "\n",
    "\n",
    "    # pf.stream(current_run)\n",
    "    # print(run_topk3)\n",
    "\n",
    "    eval_run_from_config = pf.run(\n",
    "        flow=eval_flow_path,\n",
    "        run=copilot_run_from_config,\n",
    "        data=data_path,\n",
    "        column_mapping={\n",
    "            \"question\": \"${data.question}\",\n",
    "            \"answer\": \"${data.answer}\",\n",
    "            \"reply\": \"${run.outputs.reply}\",\n",
    "            \"context\": \"${run.outputs.fetched_docs}\",\n",
    "            \"log_params\": \"${run.outputs.log_params}\",\n",
    "        },\n",
    "        display_name=\"eval_run_postgres_aistudio_scores_from_config_\" + run_time,\n",
    "    )\n",
    "    return copilot_run_from_config, eval_run_from_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0\n",
    "run_logs = {}\n",
    "for run in runs_config:\n",
    "    i += 1\n",
    "    print(runs_config[run])\n",
    "    copilot_run_from_config, eval_run_from_config = run_dags(config=runs_config[run])\n",
    "    run_logs[i] = eval_run_from_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for run_id in run_logs:\n",
    "    print(run_id)\n",
    "    pf.visualize(run_logs[run_id])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "appliedaipf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
